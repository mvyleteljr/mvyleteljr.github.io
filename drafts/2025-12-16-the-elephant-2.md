---
title: Eating the Elephant pt. 2
tldr: end-state definition
layout: post
pinned: false
---
# Intro

This is part 2 of my attempt to "Eat the Elephant", where I'm trying to make my own vivid picture of a post-AGI world. 

In this piece, I'm going after the leg, because it's close to the ground. 

## End-State Definition

I need a framework for understanding about AI capabilities post-AGI. Best I can imagine right now is to think through the question along two boundaries:
1. Cognitive Power: How much the model knows
2. Actuator Power: How much the model can touch

## Cognitive Boundary

The rough cognitive boundary definition is that *anything fundamentally derivable is derivable given sufficient data and compute*.

We already live in a space where enough compute and date would allow us to fundamentally derive any information, b. 

The classic example is a dice roll. Feels random, but if you know the exact launch angle, shape angle, molecular structure, etc... You would be able to calculate the outcome with 100% accuracy, assuming macro-level determinism. We're just limited on is data and compute. 

To make this operational, I'll scope the cognitive boundary to only cover *human-relevant* problems and include a dynamic rate variable (economically deployable compute growing at some rate $X$) that will give us some structure. 

Therefore, in the end-state, I'll assume we've crossed the boundary when *any human-relevant* problem is fundamentally derivable with an economically feasible level of compute. 


