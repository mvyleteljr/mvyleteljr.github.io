---
title: Autonomy vs. Complexity
tldr: A mathematical formalization for evaluating agentic systems along two axes
layout: post
pinned: false
---
# Formalizing Autonomy and Complexity in Agentic Systems

## 1. Introduction

### What We're Trying to Do

This document proposes a formal framework for assessing agentic systems along two fundamental axes: **autonomy** (how independently an agent operates from human oversight) and **complexity** (how difficult the decisions it faces are). We believe these two factors are critical to understanding agentic capabilities and their implications for the future of work (at least *digital work*).

### Why Formalize?

Any formalization of autonomy and complexity involves judgment calls, given the already hazy definitions. Some judgement calls arbitrary (weighted average parameters in this aggregation scheme), some subjective (prompt specificity score). Given this, why attempt formalization at all rather than offering a purely conceptual framework?

Two reasons:

1. **Reproducible evaluation.** A formal framework with explicit variables enables consistent measurement of agentic capabilities across systems, teams, and time.
    
2. **Taxonomy over leaderboard.** Benchmark scores rank systems but obscure _what_ they can do in a more general sense. A multidimensional formalization reveals the _shape_ of capability (where a system operates, not just a flattened comparison).
    

---

## 2. Overview of Approach

We decompose agentic capability into two orthogonal dimensions:

- **Autonomy:** The degree to which an agent operates independently, measured by (a) the precision of human instruction, and (b) how much of its own operational infrastructure it can define.
    
- **Complexity:** The difficulty of the decisions an agent must make, measured by the number of variables involved and their heterogeneity.
    

These dimensions are independent. A system can be high-autonomy/low-complexity (e.g., an unsupervised agent performing simple repetitive tasks) or low-autonomy/high-complexity (e.g., a tightly supervised agent assisting with intricate multi-factor decisions).

---

## 3. Autonomy Formalization

### 3.1 Variables

| Symbol                   | Definition                                                                      | Range          |
| ------------------------ | ------------------------------------------------------------------------------- | -------------- |
| $i$                      | Expected human-intervention rate (1 = intervention every cycle)                 | $[0,1]$        |
| $s$                      | Prompt specificity (1 = maximally narrow; 0 = totally broad)                    | $[0,1]$        |
| $d_p$                    | Number of distinct parameter-type schemas the agent can define                  | $\mathbb{Z}^+$ |
| $d_o$                    | Number of distinct output-type schemas the agent can define                     | $\mathbb{Z}^+$ |
| $D_p^{\max}, D_o^{\max}$ | Tunable upper bounds on schema variety                                          | $\mathbb{Z}^+$ |
| $n_{\text{env}}$         | Number of environments the agent can integrate without external help            | $\mathbb{Z}^+$ |
| $\lambda$                | Scale parameter for world-building saturation                                   | $\mathbb{R}^+$ |
| $w_p, w_o, w_g$          | Weights for input schemas, output schemas, and world-building (must sum to 1)   | $[0,1]$        |
| $\alpha, \beta$          | Weights for combining $A_{\text{intent}}$ and $A_{\text{self}}$ (must sum to 1) | $[0,1]$        |

### 3.2 Proximity to Human Intent

This component captures how much freedom the agent has relative to human instruction and oversight:

$$ A_{\text{intent}} = (1 - s)(1 - i) $$

- When prompts are narrow ($s \to 1$) or intervention is frequent ($i \to 1$), autonomy decreases.
- Maximum autonomy ($A_{\text{intent}} = 1$) occurs with broad prompts and no intervention.

### 3.3 Self-Generation Component

This component captures the agent's ability to define its own operational infrastructure.

**Schema coverage.** Normalize the agent's ability to define input and output schemas:

$$ p = \min\left(\frac{d_p}{D_p^{\max}}, 1\right), \quad o = \min\left(\frac{d_o}{D_o^{\max}}, 1\right) $$

**World-building capability.** Measure the agent's ability to integrate environments without external help using an exponential saturator:

$$ g = 1 - \exp\left(-\frac{n_{\text{env}}}{\lambda}\right) $$

- As $n_{\text{env}} \to \infty$, $g \to 1$.
- For small $n_{\text{env}}$, returns diminish according to $\lambda$.

**Combined self-generation score:**

$$ A_{\text{self}} = w_p \cdot p + w_o \cdot o + w_g \cdot g $$

Or in matrix form:

$$ A_{\text{self}} = \begin{bmatrix} w_p & w_o & w_g \end{bmatrix} \begin{bmatrix} p \ o \ g \end{bmatrix} $$

_Default weights:_ $w_p = 0.4, ; w_o = 0.2, ; w_g = 0.4$

### 3.4 Overall Autonomy Score

Combine the two components:

$$ A_{\text{autonomy}} = \alpha \cdot A_{\text{intent}} + \beta \cdot A_{\text{self}} $$

Or in matrix form:

$$ A_{\text{autonomy}} = \begin{bmatrix} \alpha & \beta \end{bmatrix} \begin{bmatrix} A_{\text{intent}} \ A_{\text{self}} \end{bmatrix} $$

_Default weights:_ $\alpha = 0.5, ; \beta = 0.5$

---

## 4. Complexity Formalization

### 4.1 Background

Complexity measurement has deep roots in information theory, notably Kolmogorov complexity and Shannon entropy. We intentionally simplify here, using pairwise Euclidean distance as a tractable proxy for variable heterogeneity. For theoretical grounding on this approach, see Xu et al. (2023), "A Complexity-Based Theory of Compositionality."

### 4.2 Variables

|Symbol|Definition|
|---|---|
|$n$|Total number of decisions|
|$m_i$|Number of variables involved in decision $i$|
|${v_{i,1}, \dots, v_{i,m_i}} \subset \mathbb{R}^d$|Vector representations of variables in decision $i$|
|$\tau$|Scale parameter for difficulty saturation|

### 4.3 Decision Difficulty

For each decision $i$, compute:

**Disparity** (average pairwise distance between variables):

$$ h_i = \frac{1}{\binom{m_i}{2}} \sum_{1 \le j < k \le m_i} |v_{i,j} - v_{i,k}| $$

**Difficulty** (saturating function of variable count and disparity):

$$ D_i = 1 - \exp\left(-\frac{m_i \cdot h_i}{\tau}\right) $$

### 4.4 Overall Complexity Score

The overall complexity is the product of individual decision difficulties:

$$ C = \prod_{i=1}^{n} D_i $$

In log form:

$$ \log C = \sum_{i=1}^{n} \log D_i $$

### 4.5 Alternative: Entropy-Based Disparity

For non-vector or categorical variables, disparity can be measured via entropy:

$$ h_i = -\sum_{c} p(c) \log p(c) $$

where $p(c)$ is the fraction of variables in category $c$.

---

## 5. Limitations and Open Questions

**Subjectivity in parameters.** Several inputs require judgment: prompt specificity ($s$), weight parameters, and scale factors ($\lambda$, $\tau$). We flag these as tunable rather than claiming objectivity.

**Performance is not captured.** This framework measures the _operational space_ an agent occupies, not how well it performs within that space. A system attempting high-autonomy, high-complexity tasks while failing most of them would score the same as one succeeding. A separate performance axis may be needed.

**Benchmarking.** An interesting extension would be to chart existing models using this framework, potentially drawing on results from benchmarks like AgentBench or tau-bench.

---

## 6. References

- Leike et al. (2018). _Scalable Agent Alignment via Reward Modeling._ https://arxiv.org/abs/1811.07871
- Shi et al. (2023). _AgentBench: Evaluating Foundation Models as Agents._ https://arxiv.org/abs/2308.03688
- Yao et al. (2022). _Planning with Language Models for Code Generation._ https://arxiv.org/abs/2303.05510
- Xu et al. (2023). _A Complexity-Based Theory of Compositionality._ https://arxiv.org/abs/2308.11189

---

## Appendix: Interactive Tools

- Desmos graph for complexity function: https://www.desmos.com/calculator/jslfqw1aam?tour=restrictions