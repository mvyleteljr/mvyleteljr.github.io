---
title: Eating the Elephant pt. 1
tldr: crafting the end-state and deciding if it's okay or not
layout: post
pinned: false
---
# The Elephant

I don't know why there is an "*elephant* in the room" and not an armadillo or something. Both would be hard to avoid in most situations. I suppose it's because the elephant is bigger and therefore much harder to avoid. It's right to not avoid the elephant in the room. It probably doesn't want to be there and was only moved there via force or manipulation. We should pay attention to it if for no other reason than to move it to a more comfortable location. 

It's also strange that the elephant shows up in that weird adage: **There is only one way to eat an elephant: one bite at a time**!

"Quick, think of anything other than a *pink elephant*!" you have also likely heard...

Anywho, my recent elephant roommate is "human flourishing in the utopian vision of AI". It is has been with me for some time and I do intend to eat it. It is not pink. 

## What's the Opposite of a Doomer? 

I'm growing increasingly uncomfortable with the way people talk about the promised "age of abundance" supposedly on the way once we unlock AGI. 

As I've briefly written about [before](https://mvyleteljr.github.io/blog/tech-telos-2025-12-29), it seems to me that this implies such an obvious question of *what this age of abundance actually looks like* and I have not seen a clear answer. 

I legitimately think this is most people's mental image when discussing the "age of prosperity" or the "end of work" or "abundance":

![Feature Tree concept sketch](/assets/images/utopia.png)

*(I think that person is walking a robot dog)* 

Who wants this? What are all of those buildings for? Does that guy have a job? Is there a ban on building with wood? What is he gonna do when he gets home?

The doomers have done a good job of creating an image of what happens if we accidentally Manhattan Project an unaligned superintelligence, but the optimists have done a comparatively terrible job describing their version of the story. 

This is a *huge* problem for the industry. Vivid stories are powerful, and without an equally imaginative positive image, the social antibodies resisting change are going to be incredibly strong. The lack of a concrete positive image is also unsettling for those working *within* the industry. I'd bet there's far more ambivalence about AI than many working on it would be willing to admit publicly. 

My goal for starting this series is to try crafting a high-res image that gives us more clarity about what it means to be human in the end-state of AI.

To do this, I want to try answering some *real* questions.

What happens to the instinctive human drive to create power hierarchies when material scarcity disappears? Does social mobility become meaningless or does a permanent underclass calcify, real or perceived? What happens to art when there's no friction between idea and execution? Where do creative impulses even *come from* if not from tension? Does religious practice balloon when work no longer structures our days and meaning gets disrupted? Will there be any human participants in financial markets, or do we just... opt out of that game? What does "currency" mean in the end-state? What does a post-capitalist economic engine look like?

I genuinely don't have a good answer to any of these questions, which is kinda my main point here. 

My goal for this series is to try getting some answers and seeing what happens if I take the optimistic route seriously and with some more precision. 

I'll need to define a plausible end-state, trace how different domains (markets, power, meaning, identity) unfold under the physics of that world. 

I suspect that this will boil down to a question of meaning. That's a 10,000-year-old question, and I'm totally at sea with how to scope it, which seems appropriate.

Interested to see what unfolds...
