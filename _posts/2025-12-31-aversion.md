---
title: AI Aversion
tldr: software engineers see AI improving their lives, most don't
layout: post
pinned: false
---
## AI Aversion // Life Nurturing

There is nothing more important than nurturing, attending to, and pouring energy into the continuation and development of *life*. Complexities aside for the moment, a good act is therefore one that after careful analysis of the best information available, is on average expected to *improve* life, and a bad act is one that *harms* it. 

Obviously, I'm glossing over a lot of nuance here, and I recognize that *improve* and *harm* are carrying a heavy load, but I think one way to understand AI aversion is to understand that it's quite difficult for the average user to see clear "life improvement" as a result of the technology.

I'd imagine that even the people using it casually to write emails or automate rote processes for themselves are (probably) not convinced it's actually improving their lives. There is a small, but non-negligible, spiritual tax incurred when using it to automate your livelihood, especially in cases where it is not expected that you are doing so. A strange dissonance emerges here because in some way, your life *is* improving: you don't have to spend as much time doing things you don't want to do. But you're also clearly making a case against your self-worth by outsourcing your mind to a piece of software, in many cases.

This has been interesting to see play out in software engineering. There were many skeptics at the beginning, and the aversion to letting AI touch one's codebase was real, even amongst enthusiasts. However, since the technology has improved, every software engineer I know that can drive AI assistants well is currently experiencing a drastic improvement in their lives. They can experiment faster, find more complex problems to work on, automate the tedious parts, and their creative expression is much more fluid.

To engineers, AI is quite obviously improving their lives. It nurtures creativity in their chosen medium, and gives them the freedom to contribute across disparate stacks that would previously have been inaccessible. (Thinking about this [tweet](https://x.com/mitchellh/status/2006114026191769924))  

Understanding the impact of technology is obviously the most difficult, complicated, and seemingly intractable problem of our time, but I likr using this simple heuristic to start teasing apart ways to think through it. 

Simple answers to simple questions.

I'm not convinced the industry is interested in asking these questions. 

It seems that the prevailing narrative is that giving open access to brain augmentation technology will allow everyone to have the software engineer experience. The promise is that you'll be able to be more powerful, explore your creativity even further, and you'll have to spend a fraction of the time doing things you don't want to do.

But the question is if that actually nurtures life, or does it simply leave us staring at the realization that there isn't really that much we want to do? 







